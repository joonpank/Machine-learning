{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa01c26-230b-45d1-90e2-e8602620c7b5",
   "metadata": {},
   "source": [
    "# Project for different classifiers\n",
    "\n",
    "In this project I will be using iris dataset from sklearn datasets library and use three different classifier methods for classifying the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2edc86f-2d0f-41fe-97bc-8e0c45fd0edf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset\n",
    "\n",
    "For this dataset there exists 3 different classes with 50 samples in each class, 150 samples total. The dimensionality of dataset is 4 and features being \"true\" and \"false\".\n",
    "\n",
    "The three different classes are **setosa, versicolor, virginica.**\n",
    "\n",
    "Our goal is to distinct each class using machine learning classification and three (3) different classifier to get the desired results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33905b7c-0c82-4a22-b187-bd496c914af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_recall_fscore_support, precision_score, recall_score\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58fe171-0fb8-4c9b-af9a-8fc08ddc8eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers\n",
    "kernel = 1.0 * RBF([1.0])\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "gauss = GaussianProcessClassifier(kernel=kernel)\n",
    "forest = RandomForestClassifier(max_depth=4, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c541be7a-86a1-44fc-8125-30c18ff9c428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = np.array(iris.target, dtype=int)\n",
    "\n",
    "# test and train split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be72d5d-15ea-47ab-83e6-8fa1711afe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the models\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "gauss.fit(X_train, y_train)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5720f352-d174-43cb-81b0-924d7878ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for each model\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_knn\n",
    "\n",
    "y_pred_gauss = gauss.predict(X_test)\n",
    "y_pred_gauss\n",
    "\n",
    "y_pred_forest = forest.predict(X_test)\n",
    "y_pred_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2045bda5-5366-484f-883c-df2af2789371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation of prediction to test data\n",
    "\n",
    "def evaluate_metrics(test, prediction):\n",
    "    results_pos = {}\n",
    "    results_pos['accuracy'] = accuracy_score(test, prediction)\n",
    "    precision, recall, f_beta, _ = precision_recall_fscore_support(test, prediction)\n",
    "    results_pos['recall'] = recall\n",
    "    results_pos['precision'] = precision\n",
    "    results_pos['f1score'] = f_beta\n",
    "    return results_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ff9d69-d3a5-44cb-be6d-f0a76596c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metrics for the KNN algorithm\")\n",
    "evaluate_metrics(y_test, y_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb56ab-c88b-41b7-919a-9f11d04e7b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metrics for the Gaussian algorithm\")\n",
    "evaluate_metrics(y_test, y_pred_gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2d4602-9fc3-46f2-9338-b62a6cbf513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metrics for the random forest algorithm\")\n",
    "evaluate_metrics(y_test, y_pred_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f8af23-3b55-4c17-b0e2-ff1e966658d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "\n",
    "\n",
    "# create a mesh to plot in\n",
    "h = 0.02  # step size in the mesh\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# list of classifiers\n",
    "classifiers = [knn, gauss, forest]\n",
    "\n",
    "# List of titles for each plot accordingly\n",
    "titles = [\"KNN\", \"Gaussian\", \"Random Forest\"]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "for i,  clf in enumerate(classifiers):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape((xx.shape[0], xx.shape[1], 3))\n",
    "    plt.imshow(Z, extent=(x_min, x_max, y_min, y_max), origin=\"lower\", alpha=.9)\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=np.array([\"r\", \"g\", \"b\"])[y], edgecolors=(0, 0, 0))\n",
    "    plt.title(titles[i])\n",
    "    plt.xlabel(xlabel=iris.feature_names[0])\n",
    "    plt.ylabel(ylabel=iris.feature_names[1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab168cd-eb6d-4ee8-bcd5-80dd46144d18",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "As we can see from the results above we used KNN, Gaussian and random forest algorithms for the classification. Only two features were plotted, namely sepal length and sepal width. The intensity of color indicates higher probability of data point classified to corresponding class. \n",
    "\n",
    "By comparing the results we clearly notice that each algorithm creates different kind of probability for the classification. KNN probabilities overlap somewhat with each other but in random forest there is clearly rectangular division in the classification and it provides rough classification for each class. In Gaussian classifier the probability changes smoothly according to clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36c0987-2afa-4828-89d7-53cd71826000",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "As we used the metrics to find best classifier to our model, we saw that Gaussian classifier got highest accuracy in all of the categories so it would be great option to use it in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
